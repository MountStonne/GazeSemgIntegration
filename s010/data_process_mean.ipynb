{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import lightgbm as ltb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial some global parameters\n",
    "static_end = 6246044"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s010 = pd.read_csv('data/emg.csv', header = None)\n",
    "label = pd.read_csv('data/grasp.csv', header = None)\n",
    "grasprepetition = pd.read_csv('data/grasprepetition.csv', header = None)\n",
    "\n",
    "\n",
    "s010_static = s010.iloc[0:static_end]\n",
    "label_static = label.iloc[0:static_end]\n",
    "grasprepetition_static = grasprepetition.iloc[0:static_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6246044 entries, 0 to 6246043\n",
      "Data columns (total 12 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   0       float64\n",
      " 1   1       float64\n",
      " 2   2       float64\n",
      " 3   3       float64\n",
      " 4   4       float64\n",
      " 5   5       float64\n",
      " 6   6       float64\n",
      " 7   7       float64\n",
      " 8   8       float64\n",
      " 9   9       float64\n",
      " 10  10      float64\n",
      " 11  11      float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 571.8 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6246044 entries, 0 to 6246043\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   0       int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 47.7 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6246044 entries, 0 to 6246043\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Dtype\n",
      "---  ------  -----\n",
      " 0   0       int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 47.7 MB\n"
     ]
    }
   ],
   "source": [
    "s010_static.info()\n",
    "label_static.info()\n",
    "grasprepetition_static.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot signals and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e079836b63e4a83bac55544a78af95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa0259a6610>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa0259a67f0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa0259a6e80>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa025fd5100>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa025fd5370>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa025fd5880>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa025fd5b20>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa025fd5700>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa025fe13a0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa091799910>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa025fe1a30>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.array(s010_static.index)\n",
    "fig, ax = plt.subplots(1, figsize = (20,10))\n",
    "line1, = ax.plot(label_static*0.001)\n",
    "for i in tqdm(range(0,12)):\n",
    "    ax.plot(index, s010_static[i])\n",
    "    \n",
    "line1.set_label('label')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the grasprepetition [1,9] as raw training data, [10,12] as raw testing data\n",
    "train_index = []\n",
    "test_index = []\n",
    "for i in tqdm(range(len(grasprepetition_static))):\n",
    "    if grasprepetition_static.iloc[i,0] in [1,2,3,4,5,6,7,8,9]:\n",
    "        train_index.append(i)\n",
    "    if grasprepetition_static.iloc[i,0] in [10,11,12]:\n",
    "        test_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx = s010_static.iloc[train_index].reset_index(drop=True)\n",
    "trainy = label_static.iloc[train_index].reset_index(drop=True)\n",
    "\n",
    "testx1 = s010_static.iloc[test_index].reset_index(drop=True)\n",
    "testy1 = label_static.iloc[test_index].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx\n",
    "trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 379\n",
    "# trainx.iloc[a-379:a+1,0].mean()\n",
    "# trainx_aft_window.iloc[a-379,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add overlapping window to training data\n",
    "trainx_aft_window = deepcopy(trainx)\n",
    "trainy_aft_window = deepcopy(trainy)\n",
    "\n",
    "for i in tqdm(range(379,len(trainx))):\n",
    "    for j in range(0,12):\n",
    "        trainx_aft_window.iloc[i,j] = trainx.iloc[i-379:i+1,j].mean()\n",
    "\n",
    "trainx_aft_window = trainx_aft_window.iloc[379:len(trainx_aft_window),:]\n",
    "trainy_aft_window = trainy_aft_window.iloc[379:len(trainy_aft_window),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx_aft_window = trainx_aft_window.reset_index(drop=True)\n",
    "trainy_aft_window = trainy_aft_window.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx_aft_window\n",
    "trainy_aft_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx1\n",
    "testy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add overlapping window to testing data\n",
    "testx1_aft_window = deepcopy(testx1)\n",
    "testy1_aft_window = deepcopy(testy1)\n",
    "\n",
    "for i in tqdm(range(379,len(testx1))):\n",
    "    for j in range(0,12):\n",
    "        testx1_aft_window.iloc[i,j] = testx1.iloc[i-379:i+1,j].mean()\n",
    "\n",
    "testx1_aft_window = testx1_aft_window.iloc[379:len(testx1_aft_window),:]\n",
    "testy1_aft_window = testy1_aft_window.iloc[379:len(testy1_aft_window),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainx_aft_window = trainx_aft_window.reset_index(drop = True)\n",
    "# trainy_aft_window = trainy_aft_window.reset_index(drop= True)\n",
    "\n",
    "index = np.array(trainx_aft_window.index)\n",
    "fig, ax = plt.subplots(1, figsize = (20,10))\n",
    "line1, = ax.plot(trainy_aft_window*0.000001+0.00001)\n",
    "for i in tqdm(range(0,12)):\n",
    "    ax.plot(index, trainx_aft_window[i])\n",
    "    \n",
    "line1.set_label('label')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot testing set #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx1_aft_window = testx1_aft_window.reset_index(drop = True)\n",
    "testy1_aft_window = testy1_aft_window.reset_index(drop= True)\n",
    "\n",
    "index = np.array(testx1_aft_window.index)\n",
    "fig, ax = plt.subplots(1, figsize = (20,10))\n",
    "line1, = ax.plot(testy1_aft_window*0.000001+0.00001)\n",
    "for i in tqdm(range(0,12)):\n",
    "    ax.plot(index, testx1_aft_window[i])\n",
    "    \n",
    "line1.set_label('label')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the testing set #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the fisrt 200ms which is 385 data point\n",
    "\n",
    "# find the ten start point\n",
    "# ten_start_point is for the testing data set #2\n",
    "counter = 0\n",
    "label_number = [1,2,3,4,5,6,7,8,9,10]\n",
    "checked_label = []\n",
    "ten_start_point = []\n",
    "for i in label_number:\n",
    "    for j in tqdm(range(0, len(testy1_aft_window))):\n",
    "        if testy1_aft_window.iloc[j,0] == i:\n",
    "            if i not in checked_label:\n",
    "                counter += 1\n",
    "                checked_label.append(i)\n",
    "                ten_start_point.append(j)\n",
    "        if counter == 10:\n",
    "            break\n",
    "            \n",
    "# find the ten new end point\n",
    "# ten_end_point is for the testing data set #2\n",
    "last = 1\n",
    "ten_end_point = []\n",
    "label_number = [1,2,3,4,5,6,7,8,9,10]\n",
    "for j in label_number:\n",
    "    last = j\n",
    "    counter = 0\n",
    "    for i in tqdm(range(ten_start_point[j-1], len(testy1_aft_window))):\n",
    "        if i == len(testy1_aft_window)-1:\n",
    "            ten_end_point.append(i)\n",
    "        current = testy1_aft_window.iloc[i,0]\n",
    "        if last == current:\n",
    "            last = current\n",
    "        else:\n",
    "            last = current\n",
    "            counter += 1\n",
    "        if counter == 1:\n",
    "            ten_end_point.append(i)\n",
    "            break\n",
    "            \n",
    "testx2_aft_window = testx1_aft_window.iloc[ten_start_point[0]:ten_start_point[0]+385, :]\n",
    "testx2_aft_window = testx2_aft_window.append(testx1_aft_window.iloc[ten_end_point[0]:ten_end_point[0]+385, :])\n",
    "\n",
    "for i in range(1,10):\n",
    "#     if i == 9:\n",
    "#         testx2_aft_window = testx2_aft_window.append(testx1_aft_window.iloc[ten_start_point[i]:ten_start_point[i]+385, :])\n",
    "#         testx2_aft_window = testx2_aft_window.append(testx1_aft_window.iloc[ten_end_point[i]:220557, :])\n",
    "#         break\n",
    "    testx2_aft_window = testx2_aft_window.append(testx1_aft_window.iloc[ten_start_point[i]:ten_start_point[i]+385, :])\n",
    "    testx2_aft_window = testx2_aft_window.append(testx1_aft_window.iloc[ten_end_point[i]:ten_end_point[i]+385, :])\n",
    "\n",
    "testy2_aft_window = testy1_aft_window.iloc[ten_start_point[0]:ten_start_point[0]+385, :]\n",
    "testy2_aft_window = testy2_aft_window.append(testy1_aft_window.iloc[ten_end_point[0]:ten_end_point[0]+385, :])\n",
    "\n",
    "for i in range(1,10):\n",
    "#     if i == 9:\n",
    "#         testy2_aft_window = testy2_aft_window.append(testy1_aft_window.iloc[ten_start_point[i]:ten_start_point[i]+385, :])\n",
    "#         testy2_aft_window = testy2_aft_window.append(testy1_aft_window.iloc[ten_end_point[i]:220557, :])\n",
    "#         break\n",
    "    testy2_aft_window = testy2_aft_window.append(testy1_aft_window.iloc[ten_start_point[i]:ten_start_point[i]+385, :])\n",
    "    testy2_aft_window = testy2_aft_window.append(testy1_aft_window.iloc[ten_end_point[i]:ten_end_point[i]+385, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot testing set #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testx2_aft_window = testx2_aft_window.reset_index(drop = True)\n",
    "testy2_aft_window = testy2_aft_window.reset_index(drop= True)\n",
    "\n",
    "index = np.array(testx2_aft_window.index)\n",
    "fig, ax = plt.subplots(1, figsize = (20,10))\n",
    "line1, = ax.plot(testy2_aft_window*0.000001+0.000001)\n",
    "for i in tqdm(range(0,12)):\n",
    "    ax.plot(index, testx2_aft_window[i])\n",
    "    \n",
    "line1.set_label('label')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_model = SVC()\n",
    "# svm_model.fit(trainx,trainy)\n",
    "\n",
    "# expected1 = testy1.values.flatten()\n",
    "# predicted1 = svm_model.predict(testx1)\n",
    "# expected2 = testy2.values.flatten()\n",
    "# predicted2 = svm_model.predict(testx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# for i in range(0, len(expected1)):\n",
    "#     if expected1[i] == predicted1[i]:\n",
    "#         counter += 1\n",
    "\n",
    "# accuracy1 = counter/len(expected1)\n",
    "\n",
    "# counter = 0\n",
    "# for i in range(0, len(expected2)):\n",
    "#     if expected2[i] == predicted2[i]:\n",
    "#         counter += 1\n",
    "\n",
    "# accuracy2 = counter/len(expected2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = np.array(testy1.index)\n",
    "# fig, ax = plt.subplots(1, figsize = (20,10))\n",
    "# line1, = ax.plot(predicted1*0.0001+0.001)\n",
    "# line2, = ax.plot(expected1*0.0001+0.001)\n",
    "    \n",
    "# line1.set_label('predicted')\n",
    "# line2.set_label('expected')\n",
    "# ax.legend()\n",
    "# plt.show()\n",
    "\n",
    "# index = np.array(testy2.index)\n",
    "# fig, ax = plt.subplots(1, figsize = (20,10))\n",
    "# line1, = ax.plot(predicted2*0.0001+0.001)\n",
    "# line2, = ax.plot(expected22*0.0001+0.001)\n",
    "    \n",
    "# line1.set_label('predicted')\n",
    "# line2.set_label('expected')\n",
    "# ax.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.fit(trainx_aft_window,trainy_aft_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected1 = testy1_aft_window.values.flatten()\n",
    "predicted1 = knn_model.predict(testx1_aft_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected2 = testy2_aft_window.values.flatten()\n",
    "predicted2 = knn_model.predict(testx2_aft_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in range(0, len(expected1)):\n",
    "    if expected1[i] == predicted1[i]:\n",
    "        counter += 1\n",
    "\n",
    "accuracy1 = counter/len(expected1)\n",
    "\n",
    "counter = 0\n",
    "for i in range(0, len(expected2)):\n",
    "    if expected2[i] == predicted2[i]:\n",
    "        counter += 1\n",
    "\n",
    "accuracy2 = counter/len(expected2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1\n",
    "accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.array(testy1.index)\n",
    "fig, ax = plt.subplots(1, figsize = (20,10))\n",
    "line1, = ax.plot(predicted1*0.0001+0.001)\n",
    "line2, = ax.plot(expected1*0.0001+0.001)\n",
    "    \n",
    "line1.set_label('predicted')\n",
    "line2.set_label('expected')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightGBM_model = ltb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightGBM_model.fit(trainx_aft_window,trainy_aft_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected1 = testy1_aft_window.values.flatten()\n",
    "predicted1 = lightGBM_model.predict(testx1_aft_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected2 = testy2_aft_window.values.flatten()\n",
    "predicted2 = lightGBM_model.predict(testx2_aft_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in range(0, len(expected1)):\n",
    "    if expected1[i] == predicted1[i]:\n",
    "        counter += 1\n",
    "\n",
    "accuracy1 = counter/len(expected1)\n",
    "\n",
    "counter = 0\n",
    "for i in range(0, len(expected2)):\n",
    "    if expected2[i] == predicted2[i]:\n",
    "        counter += 1\n",
    "\n",
    "accuracy2 = counter/len(expected2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1\n",
    "accuracy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.array(testy1.index)\n",
    "fig, ax = plt.subplots(1, figsize = (20,10))\n",
    "line1, = ax.plot(predicted1*0.0001+0.001)\n",
    "line2, = ax.plot(expected1*0.0001+0.001)\n",
    "    \n",
    "line1.set_label('predicted')\n",
    "line2.set_label('expected')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP_model = MLPClassifier(random_state=1, max_iter=300).fit(trainx,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected1 = testy1.values.flatten()\n",
    "# predicted1 = MLP_model.predict(testx1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# for i in range(0, len(expected1)):\n",
    "#     if expected1[i] == predicted1[i]:\n",
    "#         counter += 1\n",
    "\n",
    "# accuracy1 = counter/len(expected1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot testing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = np.array(testy1.index)\n",
    "# fig, ax = plt.subplots(1, figsize = (20,10))\n",
    "# line1, = ax.plot(predicted1*0.0001+0.001)\n",
    "# line2, = ax.plot(expected1*0.0001+0.001)\n",
    "    \n",
    "# line1.set_label('predicted')\n",
    "# line2.set_label('expected')\n",
    "# ax.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainx.to_csv('traintestdata/trainx.csv', header=False, index=False)\n",
    "# trainy.to_csv('traintestdata/trainy.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testx1.to_csv('traintestdata/testx1.csv', header=False, index=False)\n",
    "# testy1.to_csv('traintestdata/testy1.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx_aft_window.to_csv('traintestdata/mean/trainx_mean.csv', header=False, index=False)\n",
    "trainy_aft_window.to_csv('traintestdata/mean/trainy_mean.csv', header=False, index=False)\n",
    "testx1_aft_window.to_csv('traintestdata/mean/testx1_mean.csv', header=False, index=False)\n",
    "testy1_aft_window.to_csv('traintestdata/mean/testy1_mean.csv', header=False, index=False)\n",
    "testx2_aft_window.to_csv('traintestdata/mean/testx2_mean.csv', header=False, index=False)\n",
    "testy2_aft_window.to_csv('traintestdata/mean/testy2_mean.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
